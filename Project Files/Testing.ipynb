{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf,keras,keras.losses,keras.metrics\n",
    "from  tensorflow.keras.applications  import VGG16\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import Input, Dense, concatenate, Flatten\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33000, 306)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv(\"test_USA.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26400, 305)\n",
      "(26400, 1)\n",
      "(6600, 305)\n",
      "(6600, 1)\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:, :-1]  # Select all columns except the last one\n",
    "y=data[\"GSNR_1\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#======Converting to Arrays=========\n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "X_test=np.array(X_test)\n",
    "y_test=np.array(y_test)\n",
    "#========end=======================\n",
    "#=======Reshaping Labels===========\n",
    "y_train=y_train.reshape(-1,1)\n",
    "y_test=y_test.reshape(-1,1)\n",
    "#======end========================\n",
    "#===========printing Shapes======\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "label_scaler=MinMaxScaler()\n",
    "label_scaler.fit(y_train)\n",
    "y_train=label_scaler.transform(y_train)\n",
    "y_test=label_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher= keras.models.load_model('test_USA.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher._name='teacher'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"teacher\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 305)               93330     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               78336     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,443\n",
      "Trainable params: 215,443\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "teacher.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "student= tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(305,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "student._name='student'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"student\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               39168     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,049\n",
      "Trainable params: 50,049\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "student.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self,student,teacher):\n",
    "        super(Distiller,self).__init__()\n",
    "        self.student=student\n",
    "        self.teacher=teacher\n",
    "    def compile(self,optimizer,metrics,student_loss_fn,distillation_loss_fn,alpha=0.1,temperature=3):\n",
    "        super(Distiller,self).compile(optimizer=optimizer,metrics=metrics)\n",
    "        self.student_loss_fn=student_loss_fn\n",
    "        self.distillation_loss_fn=distillation_loss_fn\n",
    "        self.alpha=alpha\n",
    "        self.temperature=temperature\n",
    "    def train_step(self,data1):\n",
    "        x,y=data1\n",
    "        teacher_predictions=self.teacher(x,training=False)\n",
    "        with tf.GradientTape() as tape:\n",
    "            student_predictions=self.student(x,training=True)\n",
    "            student_loss=self.student_loss_fn(y,student_predictions)\n",
    "            distillation_loss=self.distillation_loss_fn(tf.nn.softmax(teacher_predictions/self.temperature),tf.nn.softmax(student_predictions/self.temperature))\n",
    "            #distillation_loss=self.distillation_loss_fn((student_predictions/self.temperature),(teacher_predictions/self.temperature))\n",
    "            loss=self.alpha*student_loss+(1-self.alpha)*distillation_loss\n",
    "        modelParameters=self.student.trainable_variables\n",
    "        gradients=tape.gradient(loss,modelParameters)\n",
    "        self.optimizer.apply_gradients(zip(gradients,modelParameters))\n",
    "        self.compiled_metrics.update_state(y,student_predictions)\n",
    "        \n",
    "        results={m.name:m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {'student_loss':student_loss,'distillation_loss':distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "    def test_step(self,data1):\n",
    "        x,y=data1\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "        \n",
    "        results={m.name:m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {'student_loss': student_loss}\n",
    "        )\n",
    "        return results\n",
    "        \n",
    "    \n",
    "            \n",
    "            \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "825/825 [==============================] - 3s 2ms/step - mean_squared_error: 0.0228 - student_loss: 0.0228 - distillation_loss: 0.0000e+00\n",
      "Epoch 2/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0177 - student_loss: 0.0177 - distillation_loss: 0.0000e+00\n",
      "Epoch 3/25\n",
      "825/825 [==============================] - 3s 3ms/step - mean_squared_error: 0.0169 - student_loss: 0.0169 - distillation_loss: 0.0000e+00\n",
      "Epoch 4/25\n",
      "825/825 [==============================] - 3s 3ms/step - mean_squared_error: 0.0163 - student_loss: 0.0163 - distillation_loss: 0.0000e+00\n",
      "Epoch 5/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0152 - student_loss: 0.0152 - distillation_loss: 0.0000e+00\n",
      "Epoch 6/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0146 - student_loss: 0.0146 - distillation_loss: 0.0000e+00\n",
      "Epoch 7/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0128 - student_loss: 0.0128 - distillation_loss: 0.0000e+00\n",
      "Epoch 8/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0105 - student_loss: 0.0106 - distillation_loss: 0.0000e+00\n",
      "Epoch 9/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0077 - student_loss: 0.0077 - distillation_loss: 0.0000e+00\n",
      "Epoch 10/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0068 - student_loss: 0.0068 - distillation_loss: 0.0000e+00\n",
      "Epoch 11/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0047 - student_loss: 0.0047 - distillation_loss: 0.0000e+00\n",
      "Epoch 12/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0037 - student_loss: 0.0037 - distillation_loss: 0.0000e+00\n",
      "Epoch 13/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0037 - student_loss: 0.0037 - distillation_loss: 0.0000e+00\n",
      "Epoch 14/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0030 - student_loss: 0.0030 - distillation_loss: 0.0000e+00\n",
      "Epoch 15/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0035 - student_loss: 0.0035 - distillation_loss: 0.0000e+00\n",
      "Epoch 16/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0048 - student_loss: 0.0048 - distillation_loss: 0.0000e+00\n",
      "Epoch 17/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0032 - student_loss: 0.0032 - distillation_loss: 0.0000e+00\n",
      "Epoch 18/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0036 - student_loss: 0.0036 - distillation_loss: 0.0000e+00\n",
      "Epoch 19/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0024 - student_loss: 0.0024 - distillation_loss: 0.0000e+00\n",
      "Epoch 20/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0027 - student_loss: 0.0027 - distillation_loss: 0.0000e+00\n",
      "Epoch 21/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0030 - student_loss: 0.0030 - distillation_loss: 0.0000e+00\n",
      "Epoch 22/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0019 - student_loss: 0.0019 - distillation_loss: 0.0000e+00\n",
      "Epoch 23/25\n",
      "825/825 [==============================] - 2s 3ms/step - mean_squared_error: 0.0025 - student_loss: 0.0025 - distillation_loss: 0.0000e+00\n",
      "Epoch 24/25\n",
      "825/825 [==============================] - 2s 2ms/step - mean_squared_error: 0.0026 - student_loss: 0.0026 - distillation_loss: 0.0000e+00\n",
      "Epoch 25/25\n",
      "825/825 [==============================] - 2s 2ms/step - mean_squared_error: 0.0027 - student_loss: 0.0027 - distillation_loss: 0.0000e+00\n",
      "207/207 [==============================] - 0s 1ms/step - mean_squared_error: 0.0044 - student_loss: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004417788237333298, 2.9080927561153658e-05]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distiller=Distiller(student=student,teacher=teacher)\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=[tf.keras.metrics.MeanSquaredError()],\n",
    "    student_loss_fn=tf.keras.losses.MeanSquaredError(),\n",
    "    #distillation_loss_fn=keras.losses.MeanSquaredError(),\n",
    "    distillation_loss_fn=keras.losses.KLDivergence(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    "    \n",
    "    \n",
    ")\n",
    "distiller.fit(X_train,y_train,epochs=25)\n",
    "distiller.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
